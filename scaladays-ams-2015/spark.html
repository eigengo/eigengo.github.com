<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <title>Exercise analysis system</title>
    <meta name="description" content="Exercise in exercise analysis">
    <meta name="author" content="Jan Machacek, Martin Zapletal">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Ubuntu%20Mono:regular,bold&subset=Latin">
    <link rel="stylesheet" href="../reveal.js/css/reveal.css">
    <link rel="stylesheet" href="../reveal.js/css/theme/default.css" id="theme">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="../reveal.js/lib/css/zenburn.css">

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = '../reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>

    <style>
    ul.tiny {
    font-size: 0.55em;
    line-height: 1.3em;
    }
    </style>

    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">
        <section data-background="images/intro.jpg">
          <h1>Exercise in exercise analysis</h1>
          <p>&nbsp;</p>
          <p>Jan Macháček <a href="https://twitter.com/honzam399">@honzam399</a></p>
        </section>

        <section>
          
          
          <section>
              Apache Spark
              <br/>
              TODO: Some intro what is Spark?
              TODO: Spark Cluster!
              TODO: Distributed, fault tolerant, scalable ML!
              <br/>
              <img src="images/imgres.png">
          </section>

          <section>
            <img src="images/lift-spark.png">

          </section>

          <section>
            <pre><code data-trim class="scala">
class JobManager(
    override val master: String,
    override val config: Config)
  extends Actor 
  with Driver 
  with ActorLogging 
  with PipeToSupport {

  override def receive: Receive = {
    case BatchJobSubmit('Suggestions) ⇒
      submit(Job[SuggestionsJob], ()).pipeTo(self)
  }
}
            </code></pre>
          </section>

          <section>
              <img src="images/spark-pipeline.png"></img>
            <aside class="notes">
              <p>Spark job suggesting exercises based on various parameters. It reads history from the journal, uses trainer's (human, no less!) hints and recommended exercise programmes.</p>
              <p>The OSS version uses a linear regression classifier for muscle groups as well as for intensities.</p>
              <p>We can run resource intesive pipelines on a different cluster without affecting the main application.</p>
              <p>Often iterative algorithms, multiple runs and model evaluation to find the best model and parameters TODO: terminology.</p>
              <p>TODO: Usages of ML in the app (training models, data mining about customers as a whole or individuals, individual exercise plans, ...</p>
            </aside>
          </section>  

          <section>
            <pre><code data-trim class="scala">

val userFilter = new UserFilter()
val normalizer = new ZScoreNormalizer()
val intensityFeatureExtractor = new IntensityFeatureExtractor()
val intensityPredictor = new LinearRegression()
    .setLabelCol("label")
    .setFeaturesCol("features")
   .setPredictionCol("predictions")
            </code></pre>
            <aside class="notes">
              Possible to build complex machine learning pipelines similar to data science languages such as Matlab, R
            </aside>
          </section>  


          <section>
            <pre><code data-trim class="scala small">
              class IntensityFeatureExtractor extends Transformer {
  import IntensityFeatureExtractor._

  override def transform(dataset: DataFrame, paramMap: ParamMap): DataFrame = {
    import dataset.sqlContext.implicits._

    val useHistory = paramMap.get(useHistoryParam).get

    val labelAndFeatures = dataset
      .select("sessionProps.intendedIntensity")
      .rdd
      .map(_.getDouble(0))
      .sliding(useHistory + 1)
      .map(x => (x.head, Vectors.dense(x.tail)))
      .toDF("intensityLabel", "intensityFeatures")

    labelAndFeatures
  }
  
  override def transformSchema(schema: StructType, paramMap: ParamMap): StructType =
    StructType(Array(StructField("intensityLabel", DoubleType, true), StructField("intensityFeatures", VectorType.VectorUDT, true)))
}
            </code></pre>
          </section>

          <section>
            <img src="images/spark-pipeline-single.png">
          </section>  

          <section>
            <pre><code data-trim class="scala small">
implicit val sqlContext = new org.apache.spark.sql.SQLContext(sc)
import sqlContext.implicits._

val events = sc.eventTable().cache().toDF()

val pipeline = new Pipeline().setStages(Array(
 userFilter,
 normalizer,
 intensityFeatureExtractor,
 intensityPredictor
))

getEligibleUsers(events, sessionEndedBefore)
   .map { user => 
     val model = pipeline.fit(
       events, 
       ParamMap(ParamPair(userIdParam, user)))
     val testData = //prepare test data
     val predictions = model.transform(testData)
     submitResult(userId, predictions, config)
   }
            </code></pre>
          </section>  
        
          <section>
            <img src="images/intensity.png">
          </section>  

        </section>  

        <section>
          <section>
            How to do it instead?
          </section>

          <section>
            How to do it instead?
          </section>
        </section>  

      </div>

    </div>

    <script src="../reveal.js/lib/js/head.min.js"></script>
    <script src="../reveal.js/js/reveal.min.js"></script>

    <script>

      Reveal.initialize({
        controls: false,
        progress: true,
        history: false,
        center: false,

        theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
        transition: Reveal.getQueryHash().transition || 'fade', // default/cube/page/concave/zoom/linear/fade/none

        // Parallax scrolling
        // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
        // parallaxBackgroundSize: '2100px 900px',

        // Optional libraries used to extend on reveal.js
        dependencies: [
          { src: '../reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: '../reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: '../reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
          { src: '../reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
          { src: '../reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
          { src: '../reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
        ]
      });

    </script>

  </body>
</html>
